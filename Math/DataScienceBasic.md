# 데이터 사이언스 기초



### 데이터 분석

- 데이터 분석 순서
  1. 목적 정의 
  2. 전처리 
  3. 알고리즘 선택 및 분석 실행 
  4. 검증
- 데이터 분석을 할 때 가장 중요한 두가지는 목적을 구체적으로 정확히 정의하는 것과 데이터의 기본적인 특성과 문제를 파악
- 시각화 : 데이터를 기반으로 그린 그래프 혹은 그리는 과정
- 데이터의 기반적인 이해 없이 그래프만 그리는 것은 의미 X



### 빅데이터와 머신러닝

- 빅데이터 : 많은 양의 데이터
- 머신러닝 : 빅데이터를 이용하여 데이터를 분석하는 기법중 하나
- 최근의 빅데이터 분석을 위해 필요한 Skill
  - 통계 / 수학(선형대수)(미분) / 도구(프로그래밍 기술)

#### 머신러닝 사용법

1. 목적을 정의한다.

2. 목적에 맞는 데이터가 있어야 한다.

3. 어떤 머신러닝 기법을 쓸 지 선택한다.

   (머신러닝은 기법이지 목적이 아니다.)



### 데이터는 항상 없다. 그럼 어떻게 모으지?

- 데이터는 수집을 어떻게 했느냐에 따라 특성이 결정됨

- 모집단 : 원래 알고싶은 데이터 전체

  - 현실적으로 존재하지 않음

- 표본 : 모집단에서 일부만 뽑아낸 부분 데이터

- 샘플링 : 모집단에서 표본을 뽑는 과정

- 표집수(N) : 샘플링한 데이터 개수

  ex) 100명 => 표집수(N) = 100

- 랜덤 샘플링 : 표집 시 어떠한 기준을 두지 않고 무작위로 추출

- 데이터는 항상 표 형식이어야 분석이 가능하다.

- '요구 목적'이 무질서한 데이터를 정리할 수 있다.



### 샘플링을 잘못하면 일어나는 대참사 - 편향(bias)

- **편향(bias)** : 데이터 수집 시 특정 기준을 적용해서 데이터가 한쪽으로 치우치는 현상
- 불편향(unbiased) : 편향의 반대. 우리가 목표하는 데이터의 상태
- 랜덤 샘플링(무선 표집) : 샘플링 시 어떠한 기준을 두지 않고 무작위로 추출하는 과정. 편향을 막을 수 있는 가장 대표적인 방법 중 하나



### 기본 용어 - 모수치와 표본수치

- 모수치와 표본수치는 서로 다르다

- **모평균(μ)(뮤)** : 모집단의 평균

- **모표준편차(σ)(시그마)** : 모집단의 표준편차

- **표본평균(x̅)(엑스바)** : 표본의 평균(알파벳은 상관 없다)

- **표본표준편차(s)(에스)** : 표본의 표준편차

- **표본의 평균 = 각 표본의 데이터를 모두 더한 뒤 표본의 개수로 나눈다.**

  ![img](https://t1.daumcdn.net/cfile/tistory/99E867385B1769152C)



### 분포의 모양

- 정규분포 : 좌우대칭 종모양 형태

  평균을 중심으로 데이터가 골고루 퍼져있는 형태

- 편도 : 데이터가 한쪽으로 치우쳐져 있을 때의 분포

- 데이터가 정상임을(정규분포임을) 확인하는 이유

  1. 분석 방법들이 대부분 통계적 가정으로 모집단이 정규분포형태일 것이다 라고 가정하고 있기 때문

  2. **중심극한정리(CLT : Central Limit Theorem)**

     => N을 많이 뽑으면 확률 분포가 정규형태가 되고 이 때 표본의 평균은 모집단 평균을 따른다.



### 집중경향치

- **집중경향치** : 데이터를 대표하는 값은 누구인가를 나타내는 수치
- **평균(mean)** : 다 더해서 개수로 나눔. 수치적으로 가운데를 의미
- **중앙치(median)** : 제일 낮은 수치부터 제일 높은 수치까지 정렬. 순서가 가운데인 것
- 최빈치 : 데이터 개수가 가장 많은 값 (중복값 존재)



### 분산과 표준편차

- 분포와 집중경향치만으로는 데이터의 특성을 다 알 수 없다.

  ex) 데이터 A = [1, 2, 3, 4, 5]

  	  데이터 B = [1, 3, 5]

  분포와 집중경향치는 같지만 그렇다고 같은 데이터는 아니다.

- **편차** : 평균에서 각 데이터까지의 거리

  ex) A = [1, 3, 5]  => 3에서 1까지의 거리는 -2고 5까지의 거리는 2다.

- 편차 거리의 합은 항상 0 이다.

  Σ(X - μ) = 0

- 분산과 표준편차를 구하는 목적은 데이터의 각 수치들이 평균에 수렴하느지, 아니면 알아서 넓게 흩어져 있는지 정도를 알려고 하는 것

- **분산** : 편차를 다 제곱해서 평균을 낸 것

$$
{\Sigma(X-\mu)^2 \above 1pt N} = \sigma^2(분산)
$$

![분산](https://user-images.githubusercontent.com/58559786/85148782-7d439200-b28b-11ea-88f6-54fbf725fc81.PNG)

- 표준편차 : 분산을 구한 후에 다시 루트를 씌운 값(분산의 제곱근)

$$
\sqrt{\Sigma(X-\mu)^2 \above 1pt N} = \sigma(표준편차)
$$

![표준편차](https://user-images.githubusercontent.com/58559786/85148903-a532f580-b28b-11ea-8330-3f0a32b823c5.PNG)

- 분산, 표준편차와 데이터와의 관계는 분산 또는 표준편차가 크면 데이터는 **평균에 수렴되지 않고 넓게 퍼져있는 형태**이다.

  그 반대로 작으면 데이터는 평균에 수렴한다.

### 아웃라이어(outlier)

- 다른 데이터들에 비해 극단적으로 크거나 작은 수치

- 평균, 중앙치, 최대, 최소, 편차 등 각종 수치를 확인하면서 파악해야 한다.

- 아웃라이어는 결과를 왜곡하므로 반드시 제거 후 분석

- 아웃라이어는 분야를 막론하고 모든 데이터에 존재한다.

  ex) 통계청이 발표한 20대 평균 월급 = 281만원..? 중앙치 210만

  ​	금수저 등의 이유로 소득이 1000만 이상도 있으므로 극단적인 차이.



### 데이터 확인과 기술통계

- 목적 정의 : 분석 목적을 명확하게 정의

- 데이터 확인 : 정의된 분석 목적을 보면서 더 고려할 점은 없는지, 부족한 데이터는 없는지 확인

- 데이터 구조 파악 : 컬럼명, 각 데이터의 타입, 기술통계

- 데이터 분석을 할 때 가장 중요한 것은?

  => 요구조건 정확히 정의하기

- 데이터의 문제점 확인

  - 편향(bias) : 목표에 맞게 제대로 샘플링 된 데이터인가?
  - 아웃라이어(outlier) : 분석 결과를 왜곡시키는 수치가 있지 않는가?



### 결측치 처리

- 결측치 : Null, NaN

  - 필요 없거나 쓸모 없는 컬럼(열) 정리
    - 샘플 개수가 너무 적거나 아예 없는 컬럼은 버림
  - 결측치 정리
    - 각 컬럼별로 N(개수)이 다르다면 결측치 존재
    - 각 컬럼 중 어느 하나라도 빈 값이 있는 행은 그냥 버림

  

### 흔히 저지르는 실수

- ex) 요일별 매출 비교
- 목표 : 조건 간 차이를 구해라
- 조건간 차이 검증
  - 샘플의 기술통계로 그래프만 그려서 판단하는 것은 객관적인 방법이 아니며, 잘못된 판단을 할 가능성이 높음 (샘플데이터의 특성만 알려주게 된다.)
  - 정확히 얼마가 차이가 있어야 차이가 있다고 할 지 '차이값'에 대한 객관적 정의가 필요
- 우리가 진짜 원하는 것은 '모집단'의 차이 (단순 샘플데이터의 차이 X)



### 차이는 무엇으로 정의하는가? - 확률로 접근하는 이유

- 추론 / 유추
  - 샘플 데이터 간 차이로 앞으로 발생할 전체 데이터 간 차이를 유추, 추론해야 함
- 추론의 정확성
  - 추론이 틀릴 확률을 구해 추론의 정확성을 따짐
  - 추론이 틀릴 확률이 낮음 = 정확도가 높은 추론



### 확률은 어떻게 구하나 - 분포의 밑넓이와 확률

- 상대평가
  - 내가 받은 점수를 다른 사람들의 점수와 비교해야 함
  - (내 점수 - 평균)으로 판단 가능
  - (내 점수 - 평균)이 양(+)의 값으로 클수록 상대적으로 높은 점수를 기록한 것
- 분포의 밑넓이와 확률
  - 분포의 밑넓이만 구할 수 있으면 내가 원하는 구간의 밑넓이와 전체 밑넓이의 비율로 정확한 확률을 구할 수 있음

$$
{원하는 구간의 분포 밑넓이 \above 1pt 전체 분포의 밑넓이}
$$

![분포의 밑넓이와 확률](https://user-images.githubusercontent.com/58559786/85271532-e3136200-b4b5-11ea-9bbc-03af3e3b6cc8.PNG)

### 표준화

- 어떠한 특정 수치를 서로 다른 분포에서 비교하기 위해 편차를 표준편차로 나눠서 표준편차의 단위로 나타내는 것
- 기호로는 대문자 Z로 나타냄

$$
Z = {X-\mu(값 - 모집단 평균) \above 1pt \sigma(표준편차) }
$$

![표준화](https://user-images.githubusercontent.com/58559786/85271817-456c6280-b4b6-11ea-8613-b0ab91a4786d.PNG)

- 표준 점수(Z-score)
  - 표준화 공식에 실제로 수치를 넣어서 구해낸 수치
  - 표준점수가 높을수록 평균으로부터 멀리 떨어져 있다는 의미



### 표준정규분포

- 모든 수치, 즉 점수들을 표준화 시켜서 얻어낸 표준 점수의 평균은 항상 0, 표준편차는 항상 1

- 원래 데이터인 모집단이 정규분포이면 모든 데이터를 표준화 시켜 얻어낸 표준 점수도 정규분포 형태가 됨

- 표준정규분포

  - 모든 점수를 다 표준화하여 얻어낸 표준 점수의 분포
  - 표준화를 Z라고 나타내므로, Z분포라고도 부름
  - (표준정규분포 = Z분포)

- 표준정규분포표(Z - table)

  - 왼 폭 : 인덱스(index) : 표준점수(Z)의 소수 첫째 자리

  - 위 : 헤더(header) : 표준점수(Z)의 소수 둘째 자리

    => 표준화한 표준점수까지의 밑넓이는 별다른 수식 없이 표준정규분포표만 볼 줄 알면 구할 수 있음.



### 계산 안하고 확률 구하는 법(적분 없이)

- 분포의 밑넓이 : 확률을 구하기 위한 분포의 밑넓이를 구하려면 표준화를 진행하여 표준점수로 변경하고 그 분포의 밑넓이를 구하면 됨
- 계산 안하고 확률 구하는 법 : 표준정규분포의 특성이 밑넓이가 1이고 좌우대칭이라는 점을 생각하면 넓이를 구할 수 있다.



### 6 시그마 - 표준화의 응용

- 품질 관리 입장에서의 6시그마(매우 낮은 불량율)

- 표준정규분포표를 이용해서 특정 확률을 이루는 Z의 구간을 구해낼 수 있다.

- Z의 절대값이 커진다는 것은?

  - 표준정규분포의 양 극단으로 향함

  - -Z ~ +Z 사이의 구간을 벗어나는 영역의 확률은 점점 줄어듬

    ex) 확률 95% (밑넓이 = 0.95)		밑넓이 1, 좌우대칭

![6sigma](https://user-images.githubusercontent.com/58559786/85273051-05a67a80-b4b8-11ea-838b-436dc59b10f4.jpg)

  - 중앙 기준 녹색 영역 : 0.475, 레드 영역 : 0.025
      - Z = 1.96 = 1.96σ     => 대략 2시그마(2σ)



### 0가설 검정 - 차이가 난다는 것의 기준

- 기본적인 목표정의는 추론을 하게 되는데 추론의 옳고 그름은 내 추론이 틀릴 확률을 따져서 계산한다.

- 내가 하려던 추론과 반대되는 추론 : "0가설", (zero-hypothesis)

- 내가 하려는 추론 : "대립가설"(alternative hypothesis), Ha

- 0가설 검정 : 0가설이 참일 확률이 높은가 낮은가를 따지는 과정

  => 0가설이 참일 확률이 낮으면, 반대추론이 참일 확률이 높으므로 내 추론이 맞을 확률이 높다는 의미

  H0 = True



### 알파(α)와 p-value : 차이가 난다는 것의 기준은?

- Hａ :  μ1 ≠ μ2(또는 μ1 - μ2 ≠ 0)	: 대립가설
- H0 :  μ1 = μ2(또는 μ1 - μ2 = 0)	: 0가설
- 몇 %까지는 H0 = True다.

  - 보통 α는 0.05, 즉 5%가 관례
  - α = 0.05(5%)

![p-value](https://user-images.githubusercontent.com/58559786/85498524-e07e4d00-b61a-11ea-82a4-f9c60acedb42.jpg)

- p-value : 실제 데이터로 구해진 0가설이 참일 확률(유의 확률)

  0.05 > p : 0가설이 참일 확률이 매우 낮다.(극단으로 가고 있다.)

  - α > p : 0가설이 기각이므로 우리의 추론이 맞다.
  - α < p : 0가설 기각 불가이므로 우리의 추론은 통계적 근거가 없다.



### t 검증

- Z(표준화)를 못쓸때 대체자
- 모집단 데이터를 구할 수 없기 때문에 모평균, 모표준편차를 구할 수 없다. 따라서 Z를 쓸 수 없다.
- 그러므로 중심극한정리(CLT) 활용

$$
N이 충분하면 \bar X는 \mu에 근사한다 : {x-\mu \above 1pt \sigma} = {X-\bar X \above 1pt S} = t(표본수치)
$$

![표본수치](https://user-images.githubusercontent.com/58559786/85524712-5dbdb800-b643-11ea-9f56-e75b6af8c8a7.PNG)

s = 표본의 표준편차

- t분포표 - 왼쪽 행 = 자유도(v) = N - 1

  헤더 = 확률 기준점(α)(반쪽 기준)

  - ex) 95% => 0.05 => 0.025

- N이 N > 30인 경우 : t는 Z와 결과가 거의 같음



#### t 검증을 위한 실험 설계

- 집단간 설계(between independent)

  - 조건을 나누고 각 조건에 데이터를 배치하여 조건간 차이를 구하는 실험 설계

  - 각 조건의 결과가 서로 영향을 미치지 못하는 독립적 관계

    ex) 표본		조건 1 ㅡ 새로 만든 두통약 사용	ㅡ	조건 1 X1		평균이 같으면 효과 X

    ​	 N=100	  조건 2 ㅡ 원래대로 놔둠				 ㅡ	조건 2 X 2

- 집단 내 설계 (within, repeated, related)

  - 조건을 나누지 않고 모든 샘플이 동일한 환경에 반복 노출되는 방법의 실험설계

  - 앞의 결과가 뒤의 결과에 영향을 미친다.

    ex) Before		X1  <=  동일한 약, 기간			=> X2 	After

    ​	    표본						평균이 같으면 효과 X				표본

#### t검증을 제대로 쓰기 위한 조건

- 정규성 : 모집단이 정규분포인가?
- 독립성 : 조건을 나눴다면 서로 독립적인가?
- 등분산성 : 나눠진 조건의 분산이 서로 같은가?
- t 검증의 계산공식 : 한가지가 아니라 여러가지이며, 위 세가지를 반드시 확인해야만 어떤 계산공식을 쓸지 결정 가능
- 정상분포가 아닐때? t 검증 사용 불가
  - 비모수검증 사용



### 엑셀을 활용한 데이터 분석

- 엑셀로 비교할 때 - '옵션 => 추가기능 => 분석도구 활성화'가 필요
- 엑셀로 표준편차 구하는 함수 => stdev
- t-검정(쌍체비교) : 집단 내 설계 => 같은 데이터를 다른 조건에 노출
- t-검정(등분산 가정 두집단) : 집단간 설계 => 같은 조건에 다른 데이터(등분산성O)
- t-검정(이분산 가정 두집단) : 집단간 설계 => 같은 조건에 다른 데이터(등분산성X)



- 가설 평균차 : 0가설 검증을 위한 것이므로 0 또는 공백

  유의 수준 : 값 : 0.05

  P(T <= t) 양측 검정의 값을 보면 된다.



### 상관분석(correlation)

- 상관분석의 목적 : 데이터간의 유사도를 구하는 것
- 유사도의 정의 방법
  - 데이터간의 거리
  - 원점에서의 각도(코사인 각도)
  - 데이터의 변화 패턴

#### 상관분석(pearson-r) 기초

- Pearson - r : 데이터 변화 패턴을 이용한 유사도 계산

  ​						유사도 분석의 기초이자 가장 널리 쓰이는 알고리즘

$$
r = {서로 같이 변하는 정도 \above 1pt 서로 각기 변하는 정도} = {\Sigma xy \above 1pt \sqrt{\Sigma x^2 \Sigma y^2}}={공분산\above 1pt 분산} = {A\bigcap B \above 1pt A \bigcup B}
$$

![Pearson-r](https://user-images.githubusercontent.com/58559786/85529863-72507f00-b648-11ea-9811-cf07d906654f.PNG)
$$
\Sigma x^2 = Sx^2 = x 데이터의 분산 = \bigtriangleup x
$$

$$
\Sigma y^2 = y데이터의 분산 = \bigtriangleup y
$$

$$
\sqrt{} 를 씌웠으므로 데이터 변화량의 총량
$$

![pearson-r 2](https://user-images.githubusercontent.com/58559786/85530957-4d104080-b649-11ea-8033-d9b2b0aab42a.PNG)

- S : 표본집단의 표본편차

- Σxy : 두 데이터의 변화 패턴이 동일한 구간의 변화량만 계산

  => 공통된 변화량의 총량, 공통된 분산(공분산)



#### pearson-r과 데이터 패턴 관계

- 두 데이터의 변화 패턴이 일치할수록 두 데이터는 유사한 데이터

  계산된 수치의 최대값은 1이며 r=1이면 유사도 100%

- 두 데이터 X, Y의 상관이 rxy = 1 이 나오면 두 데이터 X, Y의 유사도는 100%라는 의미

- rxy = 1인 경우, 가장 이해하기 쉬운 두 데이터 X, Y간의 관계성은 Y=X 형태의 관계

- 두 데이터를 기울기가 양의 값(+)이고, 선형(1차방정식)으로 나타낼 수 있으면 Pearson-r로 계산되는 두 데이터의 유사도는 100%

  (절편이 바뀌어도 항상 rxy = 1)

  ex) X = 0, 1, 2, 3, 4, 5

  ​	  Y = 0, 1, 2, 3, 4, 5

  or  Y = 2, 3, 4, 5, 6, 7

  or Y = 0, 2, 4, 6, 8, 10



### 상관값에 따른 데이터의 관계성 - 유사하다는 것은?

- -1 ≤ Pearson-r ≤ 1

  \- :  감소 함수 

  \+ : 증가 함수 

  - 단지 증가함수인지 감소함수인지 방향성만을 알려준다.

    유사도의 강도를 나타내는 것이 아니다.

- 상관강도 : 유사도의 강한 정도는 lrl : 절대값을 이용해서 나타낸다.

  기울기가 바뀌어도 모든 경우 rxy = -1

- rxy = 0 즉 두 데이터 x, y의 유사도 = 0

  산포도를 그렸을 때 원형을 나타낸다 ( 방향성 X )

![상관강도](https://user-images.githubusercontent.com/58559786/85532640-d1af8e80-b64a-11ea-92d9-2c699f72c632.PNG)



- 상관강도의 기준 
  - l r l < 0.3 => 낮은 상관강도
  - 0.3 ≤ l r l < 0.7 => 보통 상관강도
  - l r l ≥ 0.7 => 높은(강한) 상관강도



### 상관값의 해석 - 오해X, 결과는 결과일 뿐

- R²스퀘어, 결정계수, 설명력, r을 제곱해서 얻을 수 있는 수치

  예측 모델의 적합도나 변수간의 설명력(%)를 나타낸다.

  ex) 신장과 체중의 r = 0.7, R² = 0.49 : 신장과 체중이 서로 49% 설명된다

  (나머지는 그 외 변수들, 식습관, 호르몬 등)

- 상관은 데이터 변화패턴을 이용하여 '유사도' 만을 구한다.

  상관관계는 인과관계를 알려주지 않는다.

  ex)  여름이되면 아이스크림이 증가하고 익사자 수도 증가한다

  ​	=> 데이터 유사도는 높으나 인과관계는 X



### 예측을 해보자

- **회귀** : 정의된 변화 패턴을 이용해서 데이터간의 관계성을 가장 잘 나타내는 방정식을 찾는 것

  통계분야 = 회귀분석(Regression) | 경제,사회학 = Data-fitting | 수학 = Modeling

- Model : 회귀의 목적인 방정식

  Parameter : Model을 구해내는데 필요한 매개변수(기울기, Y절편)

  => Model을 구하라는 뜻은 최적의 parameter를 찾으라는 의미

- **최소제곱법(LMS : Least Mean Squared)**

  실제 데이터 - 예측 데이터(예측 결과) = 오차

  오차 제곱 평균을 구한 후 최소로 만들면 최적이라 할 수 있다.

  = 오차제곱평균(MSE) : Mean Squared Error

  제곱되어 있는 값

  MSE의 제곱근을 구한 값 : RMSE(Root Mean Squared Error)

- RMSE : 예측 모델의 정확도

  => RMSE가 낮을수록 오차 평균이 작다는 의미 이므로 **'좋은 예측 모델'**



#### 회귀

- 입력 변수 개수에 따라
  - Simple regression(단순 회귀)
  - Multiple regression(다중 회귀, 중다 회귀)
- Modeling 해야하는 방정식 차수에 따라
  - Linear regression(선형 회귀)
  - Non-linear regression(비선형회귀 => (변곡점개수 +1) 차 방정식)
- 데이터 분석의 최종 목적이 예측인지 분류인지에 따라 나뉜다.
  - 분류 = 로지스틱 회귀(Logistic regression)
- 예측 모델을 만들 때 변수가 많다고 무조건 좋은건 아니다.(필요한것만)
- 전통적인 회귀 : 사람이 직접 최소제곱법에 따른 최적의 선을 공식을 이용해 구함

$$
Y=AX+B에서\ \  A=r \cdot {S\substack y \above 1pt S\substack x} \ \ B= \bar Y - \bar A \cdot \bar X
$$

​	r = 상관계수, S = 표준편차

![전통회귀](https://user-images.githubusercontent.com/58559786/85680728-86a68180-b705-11ea-9c92-08a1824d55d2.PNG)

- 머신러닝의 목적은 최적의 Parameter를 찾는 것(기계가 학습을 통해)



- 머신러닝으로 모델링하는 과정
  - Y = AX + B와 같은 학습목표를 정해준다.
  - A, B에 랜덤으로 초기값을 주고 아무렇게나 선을 그리게 한다.
  - MSE를 일일이 계산해가면서 최적값을 찾도록 학습시킨다.
- slope = 기울기, intercept = y절편



- 머신러닝을 이용한 예측

  - 실행할 때마다 결과값이 약간씩 다르다(랜덤값을 넣으므로, 최적값은 동일)
  - 학습횟수 ↓ = 최적값 X - 이러한 경우를 언더피팅(Under fitting)
  - 학습횟수가 과도하게 높으면 샘플 데이터에만 특화되버린다 오버피팅(Over fitting)

  - 최적의 학흡 횟수는 아무도 알 수 없다.
  - 요구조건, 데이터가 중요(편향, 아웃라이어 제거)
  - 데이터 전처리가 중요하다 -> 아웃라이어 존재시 = 오버슈팅
  - 예측모델은 인과관계를 설명해 주지는 않는다. 즉, 왜? 를 설명해주지 않는다.
  - 데이터의 정의가 중요