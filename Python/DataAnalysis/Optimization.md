# 최적화 ( Optimization )

- 최적화의 문제 : 함수 f의 값을 최소화하는 변수 x의 값 x\*을 찾는 것, 이때 x*을 최적화의 해라고 한다.

``` python
def f(x):
    return (x-2)**2 + 2

x1 = np.linspace(-1, 4, 100)        # -1부터 4까지 100개 뽑아냄

plt.plot(x1, f(x1))
plt.plot(2, 2, 'ro', ms=10)

plt.show()
# 최적화의 기본 개념
```

![Figure_1](https://user-images.githubusercontent.com/58559786/86784942-10a70080-c09d-11ea-9a7b-bb0fcf5ba3a9.png)

### 그리드 서치와 수치적 최적화

- 최적화 문제 : 목적 함수의 값을 가장 최소로 하는 x의 위치를 찾는 것
- 최적화 문제를 푸는 가장 간단한 방법 : x의 값을 여러번 넣어 보고 그 중에서 가장 작은 값을 선택하는 방법(grid search)
- 그리드 서치를 이용하면 목적함수의 값(예측 오차)을 찾기 위한 계산량이 상당히 많아진다.
- 목적함수의 계산량을 줄이기 위한 방법으로 수치적 최적화(numerical optimization)를 사용한다.
- 수치적 최적화 : 반복적 시행착오(trial and error)에 의해 최적화 필요조건을 만족하는 x*를 찾는 방법
  - 함수의 위치가 최저점이 될 때까지 가능한 적은 횟수로 x의 위치를 옮기는 방법
- 수치적 최적화에 필요한 알고리즘
  - 1. 어떤 위치 x를 시도한 뒤에 다음번에 시도할 위치 x를 찾는 알고리즘
    2. 현재 위치 x가 최저점인지를 판단할 수 있는 알고리즘
- 기울기 필요 조건
  - 모든 최소점은 기울기가 0이기 때문에 최소점이 되기 위해서는 기울기값이 0이어야 한다.
  - 기울기가 0이어도 최소점이 아닐 수 있다.
  - 기울기를 나타내는 벡터(함수)를 g(gradient)로 표현한다.



#### SGD(Steepest Gradient Descent) 방법

- 현재 위치 x에서의 기울기 값 g(x)만을 이용해서 다음에 시도할 위치를 알아내는 방법



